Args in experiment:
Namespace(activation='gelu', adapter_hidden=0, alpha_temp=0.5, batch_size=32, beta_scale=1.0, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, d_proj=16, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='fed_v2_192A', detach_temp=1, devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, dual_stream=False, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=5, features='M', freeze_backbone=False, freeze_geo=False, freq='h', gate_power=2, geohcan_d_model=0, gpu=0, is_training=1, itr=1, label_len=48, lambda_acl=1.0, lambda_cls=0.1, lambda_direct=1.0, lambda_geo=0.0, lambda_latent=0.001, lambda_ortho=0.001, lambda_reg=0.05, lambda_uac=1.0, learning_rate=0.0001, loss='mse', lradj='type1', model='FEDformer', model_id='fed_v2_192A', moving_avg=25, n_heads=8, no_geohcan=False, num_class=6, num_coarse=2, num_fine=6, num_kernels=6, num_workers=10, output_attention=False, patch_len=16, patience=3, pred_len=192, rbf_gamma=1.0, root_path='./dataset/ETT-small/', seq_len=96, stride=8, target='OT', task_name='long_term_forecast', test_flop=False, timesnet_d_ff=32, timesnet_d_model=32, top_k=5, train_epochs=10, train_only=False, use_amp=False, use_energy_gate=0, use_gpu=True, use_multi_gpu=False, use_proj_ln=1)
Use GPU: cuda:0
fourier enhanced block used!
modes=32, index=[2, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46]
fourier enhanced block used!
modes=32, index=[0, 2, 6, 8, 10, 13, 14, 21, 22, 23, 28, 34, 35, 36, 42, 44, 45, 52, 55, 64, 66, 67, 68, 69, 72, 73, 83, 93, 98, 115, 117, 119]
 fourier enhanced cross attention used!
modes_q=32, index_q=[1, 5, 8, 12, 15, 20, 22, 26, 28, 30, 31, 36, 37, 46, 48, 55, 63, 64, 66, 77, 78, 81, 82, 85, 88, 90, 91, 94, 97, 99, 106, 107]
modes_kv=32, index_kv=[0, 1, 4, 6, 7, 11, 12, 13, 14, 17, 18, 19, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 43, 44, 45, 46]
[Model] FEDformer | backbone_out=512 | geohcan_dim=512 | Backbone(512) → no adapter → GeoHCAN → Head → c_out(7)
>>>>>>>start training : fed_v2_192A_FEDformer_ETTh1_ftM_sl96_ll48_pl192_nf6_proj16_gamma1.0_cls0.1_reg0.05_alp0.5_fed_v2_192A_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353 M
val 2689 M
test 2689 M
>>> [GeoHCAN] K-Means init done: 307200 samples → 6 centroids (backbone=FEDformer)
Epoch: 1 | Train Loss: 0.4984498 Vali Loss: 1.0789533
Validation loss decreased (inf --> 1.078953).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 | Train Loss: 0.4373164 Vali Loss: 1.0509329
Validation loss decreased (1.078953 --> 1.050933).  Saving model ...
Updating learning rate to 5e-05
[GeoHCAN N=6] Ev:5.1 | maxSim:0.511 | u_resp:0.188 | T:0.234 | gate:0.660 | ||Q||:4.0 | L_lat:0.4326 | L_geo:0.0000
Epoch: 3 | Train Loss: 0.4226930 Vali Loss: 1.0474380
Validation loss decreased (1.050933 --> 1.047438).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 | Train Loss: 0.4167115 Vali Loss: 1.0396280
Validation loss decreased (1.047438 --> 1.039628).  Saving model ...
Updating learning rate to 1.25e-05
[GeoHCAN N=6] Ev:5.0 | maxSim:0.488 | u_resp:0.189 | T:0.254 | gate:0.658 | ||Q||:4.0 | L_lat:0.4528 | L_geo:0.0000
Epoch: 5 | Train Loss: 0.4137513 Vali Loss: 1.0408834
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
Epoch: 6 | Train Loss: 0.4122323 Vali Loss: 1.0432919
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
[GeoHCAN N=6] Ev:5.0 | maxSim:0.479 | u_resp:0.190 | T:0.257 | gate:0.657 | ||Q||:4.0 | L_lat:0.4572 | L_geo:0.0000
Epoch: 7 | Train Loss: 0.4113834 Vali Loss: 1.0424017
EarlyStopping counter: 3 out of 3
>>>>>>>testing : fed_v2_192A_FEDformer_ETTh1_ftM_sl96_ll48_pl192_nf6_proj16_gamma1.0_cls0.1_reg0.05_alp0.5_fed_v2_192A_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689 M
mse:0.4183863401412964, mae:0.4428786635398865
>>> Visualization saved to ./test_results/fed_v2_192A_FEDformer_ETTh1_ftM_sl96_ll48_pl192_nf6_proj16_gamma1.0_cls0.1_reg0.05_alp0.5_fed_v2_192A_0/
