Args in experiment:
Namespace(activation='gelu', annealing_start=0.01, annealing_step=10, batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='Exp', devices='4,5,6,7', distil=True, do_predict=False, dropout=0.05, e_layers=2, edl_loss='edl_mse', embed='timeF', embed_type=0, enc_in=7, etrans_func='softplus', factor=3, features='M', freq='h', gpu=0, hidden_dim=512, individual=False, is_training=1, itr=1, label_len=48, lambda_acl=1, lambda_cls=0.0001, lambda_direct=1, lambda_reg=1, learning_rate=0.001, loss='mse', lradj='type1', model='Informer', model_id='ETTh1_96_336', moving_avg=25, n_heads=8, num_coarse=2, num_fine=4, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/ETT-small/', seq_len=96, target='OT', test_flop=False, train_epochs=30, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False, use_span_weight=False, with_iw=True, with_kl=True, with_uc=True)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_96_336_Informer_ETTh1_ftM_sl96_ll48_pl336_lc0.0001_lr0.001_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209 M
val 2545 M
test 2545 M
	iters: 100, epoch: 1 | loss: 4.1947446
	speed: 0.0880s/iter; left time: 666.8290s
	iters: 200, epoch: 1 | loss: 4.0687990
	speed: 0.0713s/iter; left time: 533.5086s
Epoch: 1 | 30 cost time: 20.0953s
Epoch: 1, Steps: 256 | Train Loss: 5.4089831 Vali Loss: 4.3947830 Test Loss: 4.1080524
Validation loss decreased (inf --> 4.394783).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.9140971
	speed: 0.1814s/iter; left time: 1328.4026s
	iters: 200, epoch: 2 | loss: 3.8852787
	speed: 0.0690s/iter; left time: 498.1638s
Epoch: 2 | 30 cost time: 18.8981s
Epoch: 2, Steps: 256 | Train Loss: 3.7093953 Vali Loss: 4.3438423 Test Loss: 3.8147554
Validation loss decreased (4.394783 --> 4.343842).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.8437023
	speed: 0.1794s/iter; left time: 1268.2955s
	iters: 200, epoch: 3 | loss: 3.8602362
	speed: 0.0694s/iter; left time: 483.7596s
Epoch: 3 | 30 cost time: 18.9996s
Epoch: 3, Steps: 256 | Train Loss: 3.6413656 Vali Loss: 4.3182660 Test Loss: 3.7584490
Validation loss decreased (4.343842 --> 4.318266).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.7635400
	speed: 0.1787s/iter; left time: 1217.3239s
	iters: 200, epoch: 4 | loss: 3.7995732
	speed: 0.0664s/iter; left time: 445.8226s
Epoch: 4 | 30 cost time: 18.8102s
Epoch: 4, Steps: 256 | Train Loss: 3.5992628 Vali Loss: 4.3199243 Test Loss: 3.7806412
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.7583992
	speed: 0.1845s/iter; left time: 1209.5488s
	iters: 200, epoch: 5 | loss: 3.7351182
	speed: 0.0701s/iter; left time: 452.5461s
Epoch: 5 | 30 cost time: 19.4346s
Epoch: 5, Steps: 256 | Train Loss: 3.5729698 Vali Loss: 4.3133751 Test Loss: 3.7796083
Validation loss decreased (4.318266 --> 4.313375).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.7804232
	speed: 0.1799s/iter; left time: 1133.5486s
	iters: 200, epoch: 6 | loss: 3.7163892
	speed: 0.0705s/iter; left time: 437.0036s
Epoch: 6 | 30 cost time: 19.0379s
Epoch: 6, Steps: 256 | Train Loss: 3.5567399 Vali Loss: 4.3310770 Test Loss: 3.8009975
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.7271073
	speed: 0.1814s/iter; left time: 1096.6604s
	iters: 200, epoch: 7 | loss: 3.7554481
	speed: 0.0694s/iter; left time: 412.3870s
Epoch: 7 | 30 cost time: 18.9267s
Epoch: 7, Steps: 256 | Train Loss: 3.5471923 Vali Loss: 4.3171287 Test Loss: 3.7867459
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.7339563
	speed: 0.1776s/iter; left time: 1028.1855s
	iters: 200, epoch: 8 | loss: 3.7779868
	speed: 0.0706s/iter; left time: 401.6538s
Epoch: 8 | 30 cost time: 18.9120s
Epoch: 8, Steps: 256 | Train Loss: 3.5422507 Vali Loss: 4.3169919 Test Loss: 3.8083608
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_96_336_Informer_ETTh1_ftM_sl96_ll48_pl336_lc0.0001_lr0.001_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545 M
rmse:1.0179424285888672, mse:1.036206841468811, mae:0.7959190607070923, corr:[0.1824587  0.18118581 0.1798156  0.17193331 0.16382197 0.15494813
 0.15564732 0.16233906 0.1694624  0.17982593 0.18212342 0.18214178
 0.18125978 0.1785391  0.17502321 0.17003728 0.16001497 0.15842935
 0.15943153 0.15613589 0.16155246 0.16159862 0.16587475 0.16783829
 0.16782126 0.16675255 0.15996803 0.15620203 0.14284126 0.13833877
 0.13821149 0.14829917 0.15022631 0.16282275 0.16657564 0.16619465
 0.16459934 0.16066061 0.15482086 0.15160576 0.1490411  0.14562777
 0.14142561 0.14466652 0.14877181 0.14333858 0.15154491 0.14945588
 0.1551642  0.15151969 0.1536435  0.14189558 0.13276967 0.12402389
 0.12167894 0.12916626 0.1403722  0.14781837 0.15316859 0.15801781
 0.1560312  0.15321684 0.14402196 0.13791384 0.1364508  0.13500535
 0.13043603 0.13589345 0.13786528 0.13905676 0.14215401 0.14171648
 0.14777312 0.14682493 0.14691369 0.1352216  0.12532896 0.12340724
 0.12013701 0.12270615 0.13761263 0.14866798 0.1522239  0.15560684
 0.14899    0.14808893 0.14267829 0.13389076 0.13064834 0.12608968
 0.13079089 0.12746085 0.1261072  0.13294007 0.13260993 0.13506007
 0.13702138 0.13744445 0.13499531 0.12985903 0.11871088 0.11670935
 0.11185487 0.12406781 0.13047509 0.1411244  0.15222335 0.14879148
 0.14816093 0.14340757 0.13899626 0.13349263 0.13127862 0.12868926
 0.13154437 0.13410813 0.12588853 0.13651554 0.14273787 0.1438849
 0.14647925 0.14566205 0.14378244 0.1323881  0.12541562 0.11900686
 0.12057054 0.12622505 0.13702165 0.14440933 0.15208459 0.15508145
 0.15595792 0.14953448 0.14138779 0.13902146 0.1364243  0.13405621
 0.1358023  0.13690694 0.13714175 0.14000085 0.14330068 0.14460582
 0.14741613 0.14762343 0.1459907  0.13783525 0.12686144 0.11826144
 0.12091698 0.12236007 0.13517402 0.14101233 0.14930366 0.14388344
 0.14937805 0.14140368 0.13433532 0.1245179  0.12570801 0.1256485
 0.12555932 0.13006738 0.13152298 0.13115035 0.1355156  0.14285325
 0.1431981  0.14201823 0.13994779 0.1352896  0.12440789 0.11482736
 0.11689593 0.12033323 0.13345987 0.14208841 0.1462539  0.14890136
 0.14985768 0.14049014 0.13692208 0.12887    0.12778023 0.12322208
 0.12425982 0.13243043 0.12832539 0.136514   0.13763297 0.14378875
 0.14810058 0.14396508 0.14503409 0.14073752 0.12459632 0.12214019
 0.12173208 0.13039933 0.13929787 0.14425005 0.14955357 0.15292822
 0.14911291 0.14012685 0.12942657 0.12153381 0.11440645 0.11791162
 0.11762637 0.11581103 0.11790281 0.12267625 0.12760918 0.12647687
 0.13004813 0.1376745  0.12562227 0.12513326 0.11722722 0.1124777
 0.1094407  0.116265   0.12680493 0.1314891  0.13924977 0.14068687
 0.1368457  0.12786235 0.12177908 0.11595886 0.11014418 0.10731082
 0.10735932 0.10883451 0.11086341 0.11407786 0.11754058 0.12143534
 0.12643918 0.12599245 0.1261783  0.12075145 0.10987981 0.10417426
 0.1014479  0.10833366 0.1134541  0.12325206 0.12554665 0.12518844
 0.1224452  0.11926515 0.11140215 0.10844007 0.10383219 0.10103807
 0.10339691 0.10386927 0.10719943 0.11055516 0.11502067 0.11636831
 0.12265538 0.12562211 0.1202294  0.11641599 0.11022048 0.10425398
 0.10424452 0.10899537 0.11560272 0.12045012 0.1262042  0.12549102
 0.12233438 0.11826476 0.11155453 0.10611816 0.10421252 0.09903944
 0.1017378  0.10516848 0.10519633 0.10757906 0.11352723 0.11910034
 0.12281903 0.12561539 0.11973631 0.11792757 0.10754669 0.10142811
 0.10119387 0.10284135 0.10924012 0.11508361 0.12102865 0.12239744
 0.11566593 0.11248297 0.10713679 0.10107689 0.09481416 0.09530395
 0.09367863 0.096241   0.10180505 0.10205699 0.10480279 0.10925448
 0.11587732 0.11847106 0.1154785  0.11135671 0.10161009 0.09659342
 0.09731841 0.09745131 0.10865234 0.11422881 0.11845648 0.11924035
 0.11736381 0.11240649 0.10229017 0.09653163 0.09187248 0.09430405
 0.09318091 0.09076933 0.09743693 0.09927035 0.10500455 0.10781601]
